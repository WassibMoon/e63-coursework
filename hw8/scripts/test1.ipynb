{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "input_location = 'C:/Users/Shadi/Documents/TensorFlow/word2vec/trunk/text8'\n",
    "output_location = 'text8-phrases'\n",
    "word2vec.word2phrase(input_location, output_location, verbose=False)\n",
    "#This combines commonly used bigrams together and stores them in a \"text8-phrases\" file\n",
    "word2vec.word2vec(output_location, 'text8.bin', size=100, verbose=False)\n",
    "#This creates our new bin file to run analysis on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(98331, 100)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['</s>', 'the', 'of', ..., 'dupree', 'rauchbier', 'erythropoietin'], \n",
       "      dtype='<U78')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = word2vec.load('text8.bin')\n",
    "print(model.vectors.shape)\n",
    "model.vocab\n",
    "#This loads in our model, and lets us view our vocabulary size and individual words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.16299246, -0.1238264 , -0.11257625, ...,  0.08034179,\n",
       "        -0.12345738, -0.11461086],\n",
       "       [-0.16416627,  0.08938588, -0.14227061, ..., -0.02112782,\n",
       "        -0.06445969, -0.12284703],\n",
       "       [ 0.09173124, -0.09507935, -0.02287257, ...,  0.01833546,\n",
       "        -0.04764176, -0.06384335],\n",
       "       ..., \n",
       "       [-0.10875149, -0.00702657, -0.17428397, ..., -0.08460426,\n",
       "        -0.12037898,  0.08721761],\n",
       "       [ 0.03195846,  0.04510055, -0.19919153, ..., -0.02293046,\n",
       "        -0.06679116,  0.05076638],\n",
       "       [-0.11465811,  0.00798478, -0.24047796, ...,  0.00707964,\n",
       "        -0.19194445,  0.11585018]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.vectors\n",
    "#A look at what the actual vectors look like!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('heir', 0.2987550191991549),\n",
       " ('empress', 0.2985883148142859),\n",
       " ('monarch', 0.29369429777811995),\n",
       " ('pope', 0.2926101870741759),\n",
       " ('son', 0.2904131941179186),\n",
       " ('maximilian_i', 0.2889370988723271),\n",
       " ('daughter', 0.28633576649225395),\n",
       " ('marriage', 0.28164603490563855),\n",
       " ('wife', 0.2755362695099101),\n",
       " ('priest', 0.2753066019673716)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indexes, metrics = model.analogy(pos=['emperor', 'woman'], neg=['man'], n=10)\n",
    "#Store our word index and metrics after taking emperor, adding woman, and subtracting man\n",
    "model.generate_response(indexes, metrics).tolist()\n",
    "#Compile these results in readable, list form"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Gensim API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('empress', 0.6642950177192688),\n",
       " ('roman_emperor', 0.6603520512580872),\n",
       " ('son', 0.6538196206092834),\n",
       " ('pope', 0.647287130355835),\n",
       " ('throne', 0.6456534266471863),\n",
       " ('augustus', 0.643230676651001),\n",
       " ('ruler', 0.6412137150764465),\n",
       " ('wife', 0.6397489309310913),\n",
       " ('heir', 0.6359611749649048),\n",
       " ('caliph', 0.6327414512634277)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.models import word2vec\n",
    "input_loc = 'text8-phrases'\n",
    "sentences = word2vec.Text8Corpus(input_loc)\n",
    "genmodel = word2vec.Word2Vec(sentences, min_count=10, size=100)\n",
    "#Declare our input location, generate our model. We're using the same paramaters as before.\n",
    "genmodel.most_similar(positive=['emperor','woman'], negative=['man'], topn=10)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
